{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e2b44f",
   "metadata": {},
   "source": [
    "# Testing BERT for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_version = 'bert-base-uncased'\n",
    "#bert_version = 'google-bert/bert-base-multilingual-cased'\n",
    "\n",
    "# check also: dbmdz/bert-base-italian-xxl-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12350c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentence embedding\n",
    "def get_sentence_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')  # Tokenize and prepare input tensors\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        outputs = model(**inputs)  # Get model outputs\n",
    "    \n",
    "    last_hidden_states = outputs.last_hidden_state  # Extract last hidden states\n",
    "    \n",
    "    return last_hidden_states\n",
    "    \n",
    "    sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy()  # Average token embeddings\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = get_sentence_embedding(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A fast brown fox leaps over a sleepy dog.\",\n",
    "    \"This sentence is completely different from the others.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for each example sentence\n",
    "embeddings = [get_sentence_embedding(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb04487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sentence\n",
    "query_text = \"The quick red fox jumps over the lazy dog.\"\n",
    "query_embedding = get_sentence_embedding(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text =  \"The quick brown fox jumps over the lazy dog.\",\n",
    "query_embedding = get_sentence_embedding(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3889a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarities between query and example sentences\n",
    "similarities = cosine_similarity(query_embedding, np.vstack(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print query text\n",
    "print(f\"Query text: {query_text}\")\n",
    "\n",
    "# Print similarity scores\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Similarity with '{text}': {similarities[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de877bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2402e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66489e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_llm_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a956d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_model(model_selected_index=2, current_path=\"./\") # already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = load_model(model_selected_index=2, current_path=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca035a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab68816",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = feature_extraction(\"You are a fucking retarded\")#, \"You are a fucking idiot\")\n",
    "\n",
    "embed = embed[0,0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_original = get_sentence_embedding(\"You are a fucking retarded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a251f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = feature_extraction(\"You are a fucking retarded\")#, \"You are a fucking idiot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model, local_tokenizer = load_model(model_selected_index=2, current_path=\"./\")\n",
    "text = \"You are a fucking retarded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = local_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = local_model.bert(**inputs)\n",
    "        \n",
    "embeddings = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b92c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e2314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46956448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "text = \"Voglio generare gli embedding per questa frase.\"\n",
    "\n",
    "# Ottieni gli embedding usando la pipeline\n",
    "embeddings = feature_extraction(text)\n",
    "\n",
    "# La forma dell'output sar√† [batch_size, sequence_length, hidden_size]\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Se vuoi un embedding per l'intera frase\n",
    "# Opzione 1: usa il token [CLS] (primo token)\n",
    "sentence_embedding_cls = embeddings[0, 0, :]\n",
    "# Opzione 2: media di tutti i token\n",
    "sentence_embedding_mean = torch.mean(embeddings, dim=1)\n",
    "\n",
    "print(f\"Sentence embedding shape (CLS): {sentence_embedding_cls.shape}\")\n",
    "print(f\"Sentence embedding shape (Mean): {sentence_embedding_mean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e4b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A fast brown fox leaps over a sleepy dog.\",\n",
    "    \"This sentence is completely different from the others.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for each example sentence\n",
    "embeddings = [feature_extraction(text)[0, 0, :].reshape(1, -1)  for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e2d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d560aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sentence\n",
    "query_text = \"The quick red fox jumps over the lazy dog.\"\n",
    "query_embedding = feature_extraction(query_text)[0, 0, :].reshape(1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text =  \"The quick brown fox jumps over the lazy dog.\",\n",
    "query_embedding = feature_extraction(query_text)[0, 0, :].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarities between query and example sentences\n",
    "similarities = cosine_similarity(query_embedding, np.vstack(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e331da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print query text\n",
    "print(f\"Query text: {query_text}\")\n",
    "\n",
    "# Print similarity scores\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Similarity with '{text}': {similarities[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895b0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
